- name: mkdir /tmp/calico
  file:
    path: /tmp/calico
    state: directory

- name: get calico crds
  vars:
    calico_version: v3.24.1
  get_url:
    url: "https://raw.githubusercontent.com/projectcalico/calico/{{ calico_version }}/manifests/crds.yaml"
    dest: /tmp/calico/

- name: get calicoctl
  vars:
    calicoctl_version: v3.20.0
  get_url: 
    url: "https://github.com/projectcalico/calicoctl/releases/download/{{ calicoctl_version }}/calicoctl"
    dest: "/usr/local/bin/"
    mode: +x

- name: check DATASTORE_TYPE
  shell: echo $DATASTORE_TYPE
  register: datastore

- name: set DATASTORE_TYPE
  shell: echo 'export DATASTORE_TYPE=kubernetes' >> /root/.bashrc && source /root/.bashrc
  when: datastore.stdout == ""

- name: configure IP pools
  shell:
    chdir: /tmp/calico
    cmd: |
      cat > pool1.yaml <<EOF
      apiVersion: projectcalico.org/v3
      kind: IPPool
      metadata:
        name: pool1
      spec:
        cidr: 192.168.0.0/18
        ipipMode: Never
        natOutgoing: true
        disabled: false
        nodeSelector: all()
      EOF

      cat > pool2.yaml <<EOF
      apiVersion: projectcalico.org/v3
      kind: IPPool
      metadata:
        name: pool2
      spec:
        cidr: 192.168.192.0/19
        ipipMode: Never
        natOutgoing: true
        disabled: true
        nodeSelector: all()
      EOF

      calicoctl create -f pool1.yaml
      calicoctl create -f pool2.yaml
    
- name: cni cert
  shell:
    chdir: /tmp/calico
    cmd: |
      openssl req -newkey rsa:4096 \
        -keyout cni.key \
        -nodes \
        -out cni.csr \
        -subj "/CN=calico-cni"

      openssl x509 -req -in cni.csr \
        -CA /etc/kubernetes/pki/ca.crt \
        -CAkey /etc/kubernetes/pki/ca.key \
        -CAcreateserial \
        -out cni.crt \
        -days 365

      APISERVER=$(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')
      kubectl config set-cluster kubernetes \
        --certificate-authority=/etc/kubernetes/pki/ca.crt \
        --embed-certs=true \
        --server=$APISERVER \
        --kubeconfig=cni.kubeconfig

      kubectl config set-credentials calico-cni \
        --client-certificate=cni.crt \
        --client-key=cni.key \
        --embed-certs=true \
        --kubeconfig=cni.kubeconfig

      kubectl config set-context default \
        --cluster=kubernetes \
        --user=calico-cni \
        --kubeconfig=cni.kubeconfig

      kubectl config use-context default --kubeconfig=cni.kubeconfig


- name: calico rbac
  shell:
    chdir: /tmp/calico
    cmd: | 
      cat > calico-cni-clusterrole.yaml <<EOF
      kind: ClusterRole
      apiVersion: rbac.authorization.k8s.io/v1
      metadata:
        name: calico-cni
      rules:
        # The CNI plugin needs to get pods, nodes, and namespaces.
        - apiGroups: [""]
          resources:
            - pods
            - nodes
            - namespaces
          verbs:
            - get
        # The CNI plugin patches pods/status.
        - apiGroups: [""]
          resources:
            - pods/status
          verbs:
            - patch
      # These permissions are required for Calico CNI to perform IPAM allocations.
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - blockaffinities
            - ipamblocks
            - ipamhandles
          verbs:
            - get
            - list
            - create
            - update
            - delete
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - ipamconfigs
            - clusterinformations
            - ippools
          verbs:
            - get
            - list
      EOF

      kubectl apply -f calico-cni-clusterrole.yaml
      kubectl create clusterrolebinding calico-cni --clusterrole=calico-cni --user=calico-cni

- name: install calico
  get_url:
    url: https://github.com/projectcalico/cni-plugin/releases/download/v3.14.0/calico-amd64
    dest: /opt/cni/bin/calico
    mode: +x

- name: install calico-ipam
  get_url:
    url: https://github.com/projectcalico/cni-plugin/releases/download/v3.14.0/calico-ipam-amd64
    dest: /opt/cni/bin/calico-ipam
    mode: +x

- name: mkdir /etc/cni/net.d/
  file:
    path: /etc/cni/net.d
    state: directory

- name: calico-kubecofig
  copy:
    src: /tmp/calico/cni.kubeconfig
    dest: /etc/cni/net.d/calico-kubeconfig
    mode: 0600

- name: cni config
  shell: |
    cat > /etc/cni/net.d/10-calico.conflist <<EOF
    {
      "name": "k8s-pod-network",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "calico",
          "log_level": "info",
          "datastore_type": "kubernetes",
          "mtu": 1500,
          "ipam": {
              "type": "calico-ipam"
          },
          "policy": {
              "type": "k8s"
          },
          "kubernetes": {
              "kubeconfig": "/etc/cni/net.d/calico-kubeconfig"
          }
        },
        {
          "type": "portmap",
          "snat": true,
          "capabilities": {"portMappings": true}
        }
      ]
    }
    EOF

- name: cm & secrets for calico-typha-certs
  shell:
    chdir: /tmp/calico
    cmd: |
      openssl req -x509 -newkey rsa:4096 \
                        -keyout typhaca.key \
                        -nodes \
                        -out typhaca.crt \
                        -subj "/CN=Calico Typha CA" \
                        -days 365

      kubectl create configmap -n kube-system calico-typha-ca --from-file=typhaca.crt

      openssl req -newkey rsa:4096 \
                -keyout typha.key \
                -nodes \
                -out typha.csr \
                -subj "/CN=calico-typha"

      openssl x509 -req -in typha.csr \
                        -CA typhaca.crt \
                        -CAkey typhaca.key \
                        -CAcreateserial \
                        -out typha.crt \
                        -days 365

      kubectl create secret generic -n kube-system calico-typha-certs --from-file=typha.key --from-file=typha.crt

- name: calico typha rbac
  shell:
    chdir: /tmp/calico
    cmd: |
      kubectl create serviceaccount -n kube-system calico-typha
      cat > calico-typha-clusterrole.yaml - <<EOF
      kind: ClusterRole
      apiVersion: rbac.authorization.k8s.io/v1
      metadata:
        name: calico-typha
      rules:
        - apiGroups: [""]
          resources:
            - pods
            - namespaces
            - serviceaccounts
            - endpoints
            - services
            - nodes
          verbs:
            # Used to discover service IPs for advertisement.
            - watch
            - list
        - apiGroups: ["networking.k8s.io"]
          resources:
            - networkpolicies
          verbs:
            - watch
            - list
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - globalfelixconfigs
            - felixconfigurations
            - bgppeers
            - globalbgpconfigs
            - bgpconfigurations
            - ippools
            - ipamblocks
            - globalnetworkpolicies
            - globalnetworksets
            - networkpolicies
            - clusterinformations
            - hostendpoints
            - blockaffinities
            - networksets
          verbs:
            - get
            - list
            - watch
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            #- ippools
            #- felixconfigurations
            - clusterinformations
          verbs:
            - get
            - create
            - update
      EOF

      kubectl apply -f calico-typha-clusterrole.yaml
      kubectl create clusterrolebinding calico-typha --clusterrole=calico-typha --serviceaccount=kube-system:calico-typha

- name: apply calico typha deployment
  vars:
    typha_replicas: 1
  shell:
    chdir: /tmp/calico
    cmd: |
      "
      cat > calico-typha-deployment.yaml - << EOF
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: calico-typha
        namespace: kube-system
        labels:
          k8s-app: calico-typha
      spec:
        replicas: {{ typha_replicas }}
        revisionHistoryLimit: 2
        selector:
          matchLabels:
            k8s-app: calico-typha
        template:
          metadata:
            labels:
              k8s-app: calico-typha
            annotations:
              cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'
          spec:
            hostNetwork: true
            tolerations:
              # Mark the pod as a critical add-on for rescheduling.
              - key: CriticalAddonsOnly
                operator: Exists
            serviceAccountName: calico-typha
            priorityClassName: system-cluster-critical
            containers:
            - image: calico/typha:v3.8.0
              name: calico-typha
              ports:
              - containerPort: 5473
                name: calico-typha
                protocol: TCP
              env:
                # Disable logging to file and syslog since those don't make sense in Kubernetes.
                - name: TYPHA_LOGFILEPATH
                  value: "none"
                - name: TYPHA_LOGSEVERITYSYS
                  value: "none"
                # Monitor the Kubernetes API to find the number of running instances and rebalance
                # connections.
                - name: TYPHA_CONNECTIONREBALANCINGMODE
                  value: "kubernetes"
                - name: TYPHA_DATASTORETYPE
                  value: "kubernetes"
                - name: TYPHA_HEALTHENABLED
                  value: "true"
                # Location of the CA bundle Typha uses to authenticate calico/node; volume mount
                - name: TYPHA_CAFILE
                  value: /calico-typha-ca/typhaca.crt
                # Common name on the calico/node certificate
                - name: TYPHA_CLIENTCN
                  value: calico-node
                # Location of the server certificate for Typha; volume mount
                - name: TYPHA_SERVERCERTFILE
                  value: /calico-typha-certs/typha.crt
                # Location of the server certificate key for Typha; volume mount
                - name: TYPHA_SERVERKEYFILE
                  value: /calico-typha-certs/typha.key
              livenessProbe:
                httpGet:
                  path: /liveness
                  port: 9098
                  host: localhost
                periodSeconds: 30
                initialDelaySeconds: 30
              readinessProbe:
                httpGet:
                  path: /readiness
                  port: 9098
                  host: localhost
                periodSeconds: 10
              volumeMounts:
              - name: calico-typha-ca
                mountPath: "/calico-typha-ca"
                readOnly: true
              - name: calico-typha-certs
                mountPath: "/calico-typha-certs"
                readOnly: true
            volumes:
            - name: calico-typha-ca
              configMap:
                name: calico-typha-ca
            - name: calico-typha-certs
              secret:
                secretName: calico-typha-certs
      EOF

      kubectl apply -f calico-typha-deployment.yaml
      "

- name: apply calico typha svc
  shell:
    chdir: /tmp/calico
    cmd: |
      cat > calico-typha-svc.yaml - <<EOF
      apiVersion: v1
      kind: Service
      metadata:
        name: calico-typha
        namespace: kube-system
        labels:
          k8s-app: calico-typha
      spec:
        ports:
          - port: 5473
            protocol: TCP
            targetPort: calico-typha
            name: calico-typha
        selector:
          k8s-app: calico-typha
      EOF

      kubectl apply -f calico-typha-svc.yaml

- name: calico node certs
  shell:
    chdir: /tmp/calico
    cmd: |
      openssl req -newkey rsa:4096 \
        -keyout calico-node.key \
        -nodes \
        -out calico-node.csr \
        -subj "/CN=calico-node"

      openssl x509 -req -in calico-node.csr \
        -CA typhaca.crt \
        -CAkey typhaca.key \
        -CAcreateserial \
        -out calico-node.crt \
        -days 365

      kubectl create secret generic -n kube-system calico-node-certs --from-file=calico-node.key --from-file=calico-node.crt

- name: calico node rbac
  shell:
    chdir: /tmp/calico
    cmd: |
      kubectl create serviceaccount -n kube-system calico-node

      cat > calico-node-clusterrole.yaml - <<EOF
      kind: ClusterRole
      apiVersion: rbac.authorization.k8s.io/v1
      metadata:
        name: calico-node
      rules:
        # The CNI plugin needs to get pods, nodes, and namespaces.
        - apiGroups: [""]
          resources:
            - pods
            - nodes
            - namespaces
          verbs:
            - get
        # EndpointSlices are used for Service-based network policy rule
        # enforcement.
        - apiGroups: ["discovery.k8s.io"]
          resources:
            - endpointslices
          verbs:
            - watch
            - list
        - apiGroups: [""]
          resources:
            - endpoints
            - services
          verbs:
            # Used to discover service IPs for advertisement.
            - watch
            - list
            # Used to discover Typhas.
            - get
        # Pod CIDR auto-detection on kubeadm needs access to config maps.
        - apiGroups: [""]
          resources:
            - configmaps
          verbs:
            - get
        - apiGroups: [""]
          resources:
            - nodes/status
          verbs:
            # Needed for clearing NodeNetworkUnavailable flag.
            - patch
            # Calico stores some configuration information in node annotations.
            - update
        # Watch for changes to Kubernetes NetworkPolicies.
        - apiGroups: ["networking.k8s.io"]
          resources:
            - networkpolicies
          verbs:
            - watch
            - list
        # Used by Calico for policy information.
        - apiGroups: [""]
          resources:
            - pods
            - namespaces
            - serviceaccounts
          verbs:
            - list
            - watch
        # The CNI plugin patches pods/status.
        - apiGroups: [""]
          resources:
            - pods/status
          verbs:
            - patch
        # Used for creating service account tokens to be used by the CNI plugin
        - apiGroups: [""]
          resources:
            - serviceaccounts/token
          resourceNames:
            - calico-node
          verbs:
            - create
        # Calico monitors various CRDs for config.
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - globalfelixconfigs
            - felixconfigurations
            - bgppeers
            - globalbgpconfigs
            - bgpconfigurations
            - ippools
            - ipamblocks
            - globalnetworkpolicies
            - globalnetworksets
            - networkpolicies
            - networksets
            - clusterinformations
            - hostendpoints
            - blockaffinities
          verbs:
            - get
            - list
            - watch
        # Calico must create and update some CRDs on startup.
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - ippools
            - felixconfigurations
            - clusterinformations
          verbs:
            - create
            - update
        # Calico stores some configuration information on the node.
        - apiGroups: [""]
          resources:
            - nodes
          verbs:
            - get
            - list
            - watch
        # These permissions are required for Calico CNI to perform IPAM allocations.
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - blockaffinities
            - ipamblocks
            - ipamhandles
          verbs:
            - get
            - list
            - create
            - update
            - delete
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - ipamconfigs
          verbs:
            - get
        # Block affinities must also be watchable by confd for route aggregation.
        - apiGroups: ["crd.projectcalico.org"]
          resources:
            - blockaffinities
          verbs:
            - watch
      EOF

      kubectl apply -f calico-node-clusterrole.yaml
      kubectl create clusterrolebinding calico-node --clusterrole=calico-node --serviceaccount=kube-system:calico-node

- name: apply calico node deployment
  shell:
    chdir: /tmp/calico
    cmd: |
      cat > calico-node-deployment.yaml - <<EOF
      kind: DaemonSet
      apiVersion: apps/v1
      metadata:
        name: calico-node
        namespace: kube-system
        labels:
          k8s-app: calico-node
      spec:
        selector:
          matchLabels:
            k8s-app: calico-node
        updateStrategy:
          type: RollingUpdate
          rollingUpdate:
            maxUnavailable: 1
        template:
          metadata:
            labels:
              k8s-app: calico-node
          spec:
            nodeSelector:
              kubernetes.io/os: linux
            hostNetwork: true
            tolerations:
              # Make sure calico-node gets scheduled on all nodes.
              - effect: NoSchedule
                operator: Exists
              # Mark the pod as a critical add-on for rescheduling.
              - key: CriticalAddonsOnly
                operator: Exists
              - effect: NoExecute
                operator: Exists
            serviceAccountName: calico-node
            # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
            # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
            terminationGracePeriodSeconds: 0
            priorityClassName: system-node-critical
            containers:
              # Runs calico-node container on each Kubernetes node.  This
              # container programs network policy and routes on each
              # host.
              - name: calico-node
                image: calico/node:v3.20.0
                env:
                  # Use Kubernetes API as the backing datastore.
                  - name: DATASTORE_TYPE
                    value: "kubernetes"
                  - name: FELIX_TYPHAK8SSERVICENAME
                    value: calico-typha
                  # Wait for the datastore.
                  - name: WAIT_FOR_DATASTORE
                    value: "true"
                  # Set based on the k8s node name.
                  - name: NODENAME
                    valueFrom:
                      fieldRef:
                        fieldPath: spec.nodeName
                  # Choose the backend to use.
                  - name: CALICO_NETWORKING_BACKEND
                    value: bird
                  # Cluster type to identify the deployment type
                  - name: CLUSTER_TYPE
                    value: "k8s,bgp"
                  # Auto-detect the BGP IP address.
                  - name: IP
                    value: "autodetect"
                  # Disable file logging so kubectl logs works.
                  - name: CALICO_DISABLE_FILE_LOGGING
                    value: "true"
                  # Set Felix endpoint to host default action to ACCEPT.
                  - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
                    value: "ACCEPT"
                  # Disable IPv6 on Kubernetes.
                  - name: FELIX_IPV6SUPPORT
                    value: "false"
                  # Set Felix logging to "info"
                  - name: FELIX_LOGSEVERITYSCREEN
                    value: "info"
                  - name: FELIX_HEALTHENABLED
                    value: "true"
                  # Location of the CA bundle Felix uses to authenticate Typha; volume mount
                  - name: FELIX_TYPHACAFILE
                    value: /calico-typha-ca/typhaca.crt
                  # Common name on the Typha certificate; used to verify we are talking to an authentic typha
                  - name: FELIX_TYPHACN
                    value: calico-typha
                  # Location of the client certificate for connecting to Typha; volume mount
                  - name: FELIX_TYPHACERTFILE
                    value: /calico-node-certs/calico-node.crt
                  # Location of the client certificate key for connecting to Typha; volume mount
                  - name: FELIX_TYPHAKEYFILE
                    value: /calico-node-certs/calico-node.key
                securityContext:
                  privileged: true
                resources:
                  requests:
                    cpu: 250m
                lifecycle:
                  preStop:
                    exec:
                      command:
                      - /bin/calico-node
                      - -shutdown
                livenessProbe:
                  httpGet:
                    path: /liveness
                    port: 9099
                    host: localhost
                  periodSeconds: 10
                  initialDelaySeconds: 10
                  failureThreshold: 6
                readinessProbe:
                  exec:
                    command:
                    - /bin/calico-node
                    - -bird-ready
                    - -felix-ready
                  periodSeconds: 10
                volumeMounts:
                  - mountPath: /lib/modules
                    name: lib-modules
                    readOnly: true
                  - mountPath: /run/xtables.lock
                    name: xtables-lock
                    readOnly: false
                  - mountPath: /var/run/calico
                    name: var-run-calico
                    readOnly: false
                  - mountPath: /var/lib/calico
                    name: var-lib-calico
                    readOnly: false
                  - mountPath: /var/run/nodeagent
                    name: policysync
                  - mountPath: "/calico-typha-ca"
                    name: calico-typha-ca
                    readOnly: true
                  - mountPath: /calico-node-certs
                    name: calico-node-certs
                    readOnly: true
            volumes:
              # Used by calico-node.
              - name: lib-modules
                hostPath:
                  path: /lib/modules
              - name: var-run-calico
                hostPath:
                  path: /var/run/calico
              - name: var-lib-calico
                hostPath:
                  path: /var/lib/calico
              - name: xtables-lock
                hostPath:
                  path: /run/xtables.lock
                  type: FileOrCreate
              # Used to create per-pod Unix Domain Sockets
              - name: policysync
                hostPath:
                  type: DirectoryOrCreate
                  path: /var/run/nodeagent
              - name: calico-typha-ca
                configMap:
                  name: calico-typha-ca
              - name: calico-node-certs
                secret:
                  secretName: calico-node-certs
      EOF

      kubectl apply -f calico-node-deployment.yaml